# Porting Guide for Ansible AVD 4.x.x

Major releases of AVD can contain breaking changes. The porting guide addresses how to update your inventory
and playbooks to be compatible with new default behaviors and changed data models, when upgrading from AVD 3.x.x versions.

Users of `eos_designs` do not have to consider the changes in `eos_cli_config_gen`, since those adaptions are
built in to `eos_designs`.

## Changes to role `arista.avd.eos_designs`

### Network services variables

- `evpn_rd_type` has been removed and replaced with `overlay_rd_type`.
- `evpn_rt_type` has been removed and replaced with `overlay_rt_type`.

### Fabric variables

**BGP peer groups variables:**

The following keys under `bgp_peer_groups` have been replaced to avoid upper-case variables.

Removed keys:

```yaml
bgp_peer_groups:
  IPv4_UNDERLAY_PEERS:
  MLAG_IPv4_UNDERLAY_PEER:
  EVPN_OVERLAY_PEERS:
```

Replacement keys:

```yaml
bgp_peer_groups:
  ipv4_underlay_peers:
  mlag_ipv4_underlay_peer:
  evpn_overlay_peers:
```

TODO: Add link to data model once schema is done.

**ISIS underlay variables:**

- `isis_default_circuit_type`  default changed from `level-1-2` (EOS default) to `level-2`.

To keep EOS default isis circuit-type set:

```yaml
isis_default_circuit_type: "level-1-2"
```

!!! note
    This will now print `isis circuit-type level-1-2` in the EOS configuration matching the EOS default isis circuit-type.

### L3 Edge variables

- `l3_edge.p2p_links.[].qos_profile` default changed from `null` to now leverage `p2p_uplinks_qos_profile` as its default value.

To keep AVD 3.8 behavior set:

```yaml
l3_edge:
  p2p_links:
    - qos_profile: null
```

- `l3_edge.p2p_links.[].include_in_underlay_protocol` default changed from `false` to `true`.

To keep AVD 3.8 behavior set:

```yaml
l3_edge:
  p2p_links:
    - include_in_underlay_protocol: false
```

- `l3_edge.p2p_links.[].isis_circuit_type` -> default changed from `level-1-2` (EOS default) set by `isis_default_circuit_type` to `level-2`.

To keep AVD 3.8 behavior set:

```yaml
l3_edge:
  p2p_links:
    - isis_circuit_type: "level-1-2"
```

!!! note
    This will now print `isis circuit-type level-1-2` in the EOS configuration matching the EOS default isis circuit-type.

- `l3_edge.p2p_links.[].isis_hello_padding` default changed from `false` to `true` (EOS default).

No changes required to variables, since this matches to EOS default configuration.

!!! note
    This will now print `isis hello padding` in the EOS configuration matching the EOS default.

### Core interfaces variables

- `core_interfaces.p2p_links.[].ptp_enable` requires the `ptp.enabled: true` to be set at the fabric level.

Set the following variable at the fabric level.

```yaml
ptp:
  enabled: true
```

### Connected endpoints

The `connected_endpoints_key.[].adapters.[].server_ports` has been removed and replaced with `connected_endpoints_key.[].adapters.[].endpoint_ports` in order to be generic across endpoint types.

Removed keys:

```yaml
<connected_endpoints_keys.key>:
  - name: <str>
    adapters:
      - server_ports:
```

Replacement keys:

```yaml
<connected_endpoints_keys.key>:
  - name: <str>
    adapters:
      - endpoint_ports:
```

### IP and IPv6 routing is no longer configured on pure L2 devices

For node types like `l2leaf` where `underlay_router` is set to `false` under `node_type_keys` AVD versions below 4.0.0
still rendered `ip routing`, `ip routing ipv6 interfaces` and/or `ipv6 unicast-routing` in the configuration.
As of AVD version 4.0.0 these IP and IPv6 routing configurations are no longer configured for `l2leaf`
or other node types with `underlay_router: false`.

To retain the old behavior the inventory can be updated like this:

```yaml
l2leaf:
  defaults:
    always_configure_ip_routing: true
```

### BGP is no longer configured on irrelevant nodes

An example of an "irrelevant node" is a pure L3 Spine in L3LS running ISIS or OSPF in the underlay. As long as the spine is not
set as route-server for any overlay BGP protocol, there is no need for `router bgp <asn>` to be configured on this device.

Example of default configuration previously generated but now removed:

```eos
router bgp 65000
  router-id 192.168.255.2
  maximum-paths 4 ecmp 4
```

To retain the old behavior the inventory can be updated like this:

```yaml
spine:
  defaults:
    structured_config:
      router_bgp:
        as: '65000'
        router_id: 192.168.255.2
        maximum_paths:
          paths: 4
          ecmp: 4
```

### Link-local IPv6 addressing is implicitly enabled when configuring IPv6 Anycast IP

Per Arista best practice, all SVIs configured with `ipv6 address virtual` should also have
`ipv6 enable` configured, to use link-local IPv6 addresses for NDv6 operations.

With AVD version 4.0.0 this best practice is now implemented by default.

Example input:

```yaml
tenants:
  - name: mytenant
    <...>
    vrfs:
      - name: myvrf
        <...>
        svis:
          - id: 123
            <...>
            ipv6_address_virtuals:
              - 2001:db8:12::1/64
```

Now renders:

```eos
interface Vlan123
  <...>
  ipv6 enable                  ! <-- New command
  ipv6 address virtual 2001:db8:12::1/64
```

To retain the old behavior the inventory can be updated like this:

```yaml
tenants:
  - name: mytenant
    <...>
    vrfs:
      - name: myvrf
        <...>
        svis:
          - id: 123
            <...>
            ipv6_address_virtuals:
              - 2001:db8:12::1/64
            ipv6_enable: false # <--- Overriding the new default behavior
```

## Changes to role `arista.avd.eos_cli_config_gen`

### New model for `hardware_counters.features`

The `hardware_counters.features` model has been improved to allow more options.

TODO: add link to the full data model

Example with old data model:

```yaml
hardware_counters:
  features:
    - ip: in
    - ip: out
    - vlan-interfaces: in
```

Same example with new data model:

```yaml
hardware_counters:
  features:
    - name: ip
      direction: out
    - name: ip
      direction: in
    - name: vlan-interfaces
      direction: in
```

### New model for `ip_name_servers`

The `name_server` key has been deprecated in favor of `ip_name_servers`, more
aligned with the EOS cli.

TODO: add link to the full data model

Example with old data model:

```yaml
name_server:
  source:
    vrf: MGMT
  nodes:
    - 8.8.8.8
```

Same example with new data model:

```yaml
ip_name_servers:
  - ip_address: 8.8.8.8
    vrf: MGMT
```

### New behavior for `ip_igmp_snooping`

Disabling IGMP Snooping globally no longer blocks other IGMP snooping configuration.

Example input:

```yaml
ip_igmp_snooping:
  globally_enabled: false
  vlans:
    - id: 10
      enabled: true
    - id: 20
      enabled: false
    - id: 30
      enabled: false
```

Previous output:

```eos
no ip igmp snooping
```

AVD version 4.0.0 output:

```eos
no ip igmp snooping
ip igmp snooping vlan 10
no ip igmp snooping vlan 20
no ip igmp snooping vlan 30
```

While EOS accepts the extra configuration, IGMP snooping is still effectively disabled.
To remove the extra configuration, the inputs have to be removed like:

```yaml
ip_igmp_snooping:
  globally_enabled: false
```

### New required `enabled` key under `vlan_interfaces.[].ip_attached_host_route_export`

To avoid ambiguous YAML data input, the data model for `vlan_interfaces.[].ip_attached_host_route_export` has been updated to require
an `enabled: true` key to be added.

Example with old data model (shown with old dictionary form input):

```yaml
vlan_interfaces:
  Vlan86:
    ip_address: 10.10.83.1/24
    ip_attached_host_route_export: {}
```

Same example with new data model (shown with new list form input):

```yaml
vlan_interfaces:
  - name: Vlan86
    ip_address: 10.10.83.1/24
    ip_attached_host_route_export:
      enabled: true
```

The change has been incorporated into `eos_designs` so action is only required when defining `structured_configuration` directly.

## Changes to role `arista.avd.eos_config_deploy_cvp`

### Inventory to CloudVision containers

In AVD v4.0.0 the role get support for dynamic Ansible inventories. This means that the basis for CloudVision
containers will no longer be the `inventory.yml` file, but instead the role reads the loaded Ansible inventory.
This inventory can be loaded from dynamic inventory plugins like Ansible Automation Platform, AWX etc.

The new inventory parsing is stricter than the previous method, so all Ansible inventory groups *must* be laid
out as a regular tree structure starting from the `container_root`.

Old behavior can be retained by adding the variable `avd_inventory_to_container_file: "{{ inventory_file }}"` to the playbook task
for `arista.avd.eos_config_deploy_cvp` like this example:

```yaml
- name: Configuration deployment with CVP
  hosts: cv_servers
  connection: local
  gather_facts: false
  collections:
    - arista.avd
  tasks:
    - name: Provision CVP
      import_role:
        name: eos_config_deploy_cvp
      vars:
        container_root: 'DC1_FABRIC'
        configlets_prefix: 'AVD'
        state: present
        avd_inventory_to_container_file: "{{ inventory_file }}"  # <--- Retain old behavior from AVD v3.x.x
```

#### Supported group structure

In this example the `container_root` is set to `DC1_FABRIC`. This means that this, and all groups below will be created
as containers on CloudVision. Devices can be a member of multiple group hierarchies like `DC1_FABRIC` and `DC1_TENANT_NETWORKS`,
as long as the other hierarchies are not below group set as `container_root`.

```yaml
---
all:
  children:
    DC1:
      children:
        DC1_FABRIC:
          children:
            DC1_SPINES:
              hosts:
                DC1-SPINE1:
                DC1-SPINE2:
            DC1_L3LEAFS:
              children:
                DC1_LEAF1:
                  hosts:
                    DC1-LEAF1A:
                    DC1-LEAF1B:
                DC1_LEAF2:
                  hosts:
                    DC1-LEAF2A:
                    DC1-LEAF2B:
        DC1_TENANTS_NETWORKS:  # <--- This group is under DC1, but it is NOT under DC1_FABRIC, so this inventory is supported
          children:
            DC1_L3LEAFS:
```

#### Unsupported group structure

```yaml
---
all:
  children:
    DC1:
      children:
        DC1_FABRIC:
          children:
            DC1_SPINES:
              hosts:
                DC1-SPINE1:
                DC1-SPINE2:
            DC1_L3LEAFS:
              children:
                DC1_LEAF1:
                  hosts:
                    DC1-LEAF1A:
                    DC1-LEAF1B:
                DC1_LEAF2:
                  hosts:
                    DC1-LEAF2A:
                    DC1-LEAF2B:
            DC1_TENANTS_NETWORKS:  # <--- This group is under DC1_FABRIC, making DC1_L3LEAFS have two "parents",
              children:            #      so this inventory is *not* supported with the new inventory parser
                DC1_L3LEAFS:
```
