# Porting Guide for Ansible AVD 4.x.x

Major releases of AVD can contain breaking changes. The porting guide addresses how to update your inventory
and playbooks to be compatible with new default behaviors and changed data models, when upgrading from AVD 3.x.x versions.

Users of `eos_designs` do not have to consider the changes in `eos_cli_config_gen`, since those adaptions are
built in to `eos_designs`.

## Changes to role `arista.avd.eos_designs`

### Network services variables

- `evpn_rd_type` has been removed and replaced with `overlay_rd_type`.
- `evpn_rt_type` has been removed and replaced with `overlay_rt_type`.

### Fabric variables

The following keys under `bgp_peer_groups` have been replaced to avoid upper-case variables.

Removed keys:

```yaml
bgp_peer_groups:
  IPv4_UNDERLAY_PEERS:
  MLAG_IPv4_UNDERLAY_PEER:
  EVPN_OVERLAY_PEERS:
```

Replacement keys:

```yaml
bgp_peer_groups:
  ipv4_underlay_peers:
  mlag_ipv4_underlay_peer:
  evpn_overlay_peers:
```

TODO: Add link to data model once schema is done.

### IP and IPv6 routing is no longer configured on pure L2 devices

For node types like `l2leaf` where `underlay_router` is set to `false` under `node_type_keys` AVD versions below 4.0.0
still rendered `ip routing`, `ip routing ipv6 interfaces` and/or `ipv6 unicast-routing` in the configuration.
As of AVD version 4.0.0 these IP and IPv6 routing configurations are no longer configured for `l2leaf`
or other node types with `underlay_router: false`.

To retain the old behavior the inventory can be updated like this:

```yaml
l2leaf:
  defaults:
    always_configure_ip_routing: true
```

## Changes to role `arista.avd.eos_cli_config_gen`

### New model for `hardware_counters.features`

The `hardware_counters.features` model has been improved to allow more options.

TODO: add link to the full data model

Example with old data model:

```yaml
hardware_counters:
  features:
    - ip: in
    - ip: out
    - vlan-interfaces: in
```

Same example with new data model:

```yaml
hardware_counters:
  features:
    - name: ip
      direction: out
    - name: ip
      direction: in
    - name: vlan-interfaces
      direction: in
```

### New model for `ip_name_servers`

The `name_server` key has been deprecated in favor of `ip_name_servers`, more
aligned with the EOS cli.

TODO: add link to the full data model

Example with old data model:

```yaml
name_server:
  source:
    vrf: MGMT
  nodes:
    - 8.8.8.8
```

Same example with new data model:

```yaml
ip_name_servers:
  source:
    vrf: MGMT
  nodes:
    - 8.8.8.8
```

## Changes to role `arista.avd.eos_config_deploy_cvp`

### Inventory to CloudVision containers

In AVD v4.0.0 the role get support for dynamic Ansible inventories. This means that the basis for CloudVision
containers will no longer be the `inventory.yml` file, but instead the role reads the loaded Ansible inventory.
This inventory can be loaded from dynamic inventory plugins like Ansible Automation Platform, AWX etc.

The new inventory parsing is stricter than the previous method, so all Ansible inventory groups *must* be laid
out as a regular tree structure starting from the `container_root`.

Old behavior can be retained by adding the variable `avd_inventory_to_container_file: "{{ inventory_file }}"` to the playbook task
for `arista.avd.eos_config_deploy_cvp` like this example:

```yaml
- name: Configuration deployment with CVP
  hosts: cv_servers
  connection: local
  gather_facts: false
  collections:
    - arista.avd
  tasks:
    - name: Provision CVP
      import_role:
        name: eos_config_deploy_cvp
      vars:
        container_root: 'DC1_FABRIC'
        configlets_prefix: 'AVD'
        state: present
        avd_inventory_to_container_file: "{{ inventory_file }}"  # <--- Retain old behavior from AVD v3.x.x
```

#### Supported group structure

In this example the `container_root` is set to `DC1_FABRIC`. This means that this, and all groups below will be created
as containers on CloudVision. Devices can be a member of multiple group hierarchies like `DC1_FABRIC` and `DC1_TENANT_NETWORKS`,
as long as the other hierarchies are not below group set as `container_root`.

```yaml
---
all:
  children:
    DC1:
      children:
        DC1_FABRIC:
          children:
            DC1_SPINES:
              hosts:
                DC1-SPINE1:
                DC1-SPINE2:
            DC1_L3LEAFS:
              children:
                DC1_LEAF1:
                  hosts:
                    DC1-LEAF1A:
                    DC1-LEAF1B:
                DC1_LEAF2:
                  hosts:
                    DC1-LEAF2A:
                    DC1-LEAF2B:
        DC1_TENANTS_NETWORKS:  # <--- This group is under DC1, but it is NOT under DC1_FABRIC, so this inventory is supported
          children:
            DC1_L3LEAFS:
```

#### Unsupported group structure

```yaml
---
all:
  children:
    DC1:
      children:
        DC1_FABRIC:
          children:
            DC1_SPINES:
              hosts:
                DC1-SPINE1:
                DC1-SPINE2:
            DC1_L3LEAFS:
              children:
                DC1_LEAF1:
                  hosts:
                    DC1-LEAF1A:
                    DC1-LEAF1B:
                DC1_LEAF2:
                  hosts:
                    DC1-LEAF2A:
                    DC1-LEAF2B:
            DC1_TENANTS_NETWORKS:  # <--- This group is under DC1_FABRIC, making DC1_L3LEAFS have two "parents",
              children:            #      so this inventory is *not* supported with the new inventory parser
                DC1_L3LEAFS:
```
